{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Fluid Flow using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(x)\n",
    "    \n",
    "    name = 'basic_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    model = keras.Model(input, output, name=name)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Model: \"basic_cnn8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 64, 64, 4)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 64, 64, 8)         296       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64, 64, 8)        32        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 64, 64, 8)         584       \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 8)        32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 32, 32, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 32, 32, 16)        1168      \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 16, 16, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 16, 16, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 32, 32, 16)       2064      \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 32, 32, 16)       64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 64, 64, 8)        520       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 64, 64, 3)         27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,083\n",
      "Trainable params: 25,795\n",
      "Non-trainable params: 288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 19:17:06.232711: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-04-16 19:17:06.232895: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "basic_model = basic_cnn((64, 64, 4), 3, 8)\n",
    "basic_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(x, n_filters):\n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_down(x, n_filters):\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    skip = layers.MaxPooling2D(padding='same')(x)\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_up(x, skip, n_filters):\n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "    \n",
    "    # downsampling\n",
    "    d1, p1 = unet_down(input, n_filters)\n",
    "    d2, p2 = unet_down(p1, n_filters*2)\n",
    "    d3, p3 = unet_down(p2, n_filters*4)\n",
    "    d4, p4 = unet_down(p3, n_filters*8)\n",
    "    \n",
    "    # bottleneck\n",
    "    b = unet_conv_block(p4, n_filters*16)\n",
    "    \n",
    "    # upsampling\n",
    "    u1 = unet_up(b, d4, n_filters*8)\n",
    "    u2 = unet_up(u1, d3, n_filters*4)\n",
    "    u3 = unet_up(u2, d2, n_filters*2)\n",
    "    u4 = unet_up(u3, d1, n_filters)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(u4)\n",
    "    \n",
    "    name = 'unet{n_filters}'.format(n_filters=n_filters)\n",
    "    model = keras.Model(input, output, name=name)\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shapes: (460, 63, 64, 64, 4), (460, 63, 64, 64, 3)\n",
      "Validation Dataset Shapes: (52, 63, 64, 64, 4), (52, 63, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "fpath = 'data/sim_np/size64/sim_512x64x64x64x3.npy'\n",
    "dataset = np.load(fpath)\n",
    "fpath = 'data/sim_np/size64/bound_64x64.npy'\n",
    "boundary = np.load(fpath)\n",
    "\n",
    "# Swap the axes representing the number of frames and number of data samples.\n",
    "# dataset = np.swapaxes(dataset, 0, 1)\n",
    "# We'll pick out 1000 of the 10000 total examples and use those.\n",
    "# dataset = dataset[:1000, ...]\n",
    "# Add a channel dimension since the images are grayscale.\n",
    "# dataset = np.expand_dims(dataset, axis=-1)\n",
    "\n",
    "# # Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "# Normalize the data to the 0-1 range.\n",
    "# train_dataset = train_dataset / 255\n",
    "# val_dataset = val_dataset / 255\n",
    "\n",
    "# We'll define a helper function to shift the frames, where\n",
    "# `x` is frames 0 to n - 1, and `y` is frames 1 to n.\n",
    "def create_shifted_frames(data, boundary):\n",
    "    x = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4] + 1), np.float16)\n",
    "    y = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4]), np.float16)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1] - 1):\n",
    "            \n",
    "            x[i, j] = np.concatenate((data[i, j], np.expand_dims(boundary, axis=-1)), axis=-1)\n",
    "            y[i, j] = data[i, j + 1]\n",
    "        \n",
    "    return x, y\n",
    "\n",
    "\n",
    "# Apply the processing function to the datasets.\n",
    "x_train, y_train = create_shifted_frames(train_dataset, boundary)\n",
    "x_val, y_val = create_shifted_frames(val_dataset, boundary)\n",
    "\n",
    "# Inspect the dataset.\n",
    "print(\"Training Dataset Shapes: \" + str(x_train.shape) + \", \" + str(y_train.shape))\n",
    "print(\"Validation Dataset Shapes: \" + str(x_val.shape) + \", \" + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_frames(x):\n",
    "    return x.reshape(x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the training data.\n",
    "x_train_unroll = unroll_frames(x_train)\n",
    "y_train_unroll = unroll_frames(y_train)\n",
    "x_val_unroll = unroll_frames(x_val)\n",
    "y_val_unroll = unroll_frames(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 19:18:01.602455: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - ETA: 0s - loss: 0.9288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 19:18:18.403414: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/227 [==============================] - 19s 76ms/step - loss: 0.9288 - val_loss: 0.6194 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.5005 - val_loss: 0.4813 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "227/227 [==============================] - 15s 68ms/step - loss: 0.4311 - val_loss: 0.4180 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "227/227 [==============================] - 15s 66ms/step - loss: 0.3937 - val_loss: 0.3795 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "227/227 [==============================] - 15s 65ms/step - loss: 0.3694 - val_loss: 0.3606 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "227/227 [==============================] - 15s 68ms/step - loss: 0.3557 - val_loss: 0.3493 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "227/227 [==============================] - 16s 68ms/step - loss: 0.3418 - val_loss: 0.3360 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.3330 - val_loss: 0.3274 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "227/227 [==============================] - 15s 66ms/step - loss: 0.3229 - val_loss: 0.3172 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "227/227 [==============================] - 15s 67ms/step - loss: 0.3145 - val_loss: 0.3099 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Define modifiable training hyperparameters.\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=0)\n",
    "\n",
    "# create model to train\n",
    "model = unet((64, 64, 4), 3, 8)\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "# fit data to model\n",
    "history = model.fit(\n",
    "    x_train_unroll,\n",
    "    y_train_unroll,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (x_val_unroll, y_val_unroll),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 19:20:37.818271: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/keras/unet8/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('models/keras/{name}'.format(name=model.name))\n",
    "# model = keras.models.load_model('models/keras/unet8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate the Labels and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_input(dataset, boundary, example_i):\n",
    "    boundary = np.repeat(np.expand_dims(boundary, (0, -1)), 64, 0)\n",
    "    data = dataset[example_i]\n",
    "    return np.concatenate((data, boundary), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 19:23:09.971087: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.animation as animation\n",
    "import os \n",
    "%matplotlib inline\n",
    "\n",
    "FPS = 24\n",
    "INTERVAL = 1000.0/FPS\n",
    "NUM_EXAMPLES = val_dataset.shape[0]\n",
    "NUM_FRAMES = val_dataset.shape[1]\n",
    "MODEL_NAME = model.name\n",
    "\n",
    "for ex in range(NUM_EXAMPLES):\n",
    "    x = data_to_input(val_dataset, boundary, ex)\n",
    "    # y = model.predict(x)\n",
    "    \n",
    "    # CREATE THE LABEL VIDEO\n",
    "    fig = plt.figure()\n",
    "    label_ims = []\n",
    "    for i in range(NUM_FRAMES - 1):\n",
    "        plt.axis('off')\n",
    "        label_im = plt.imshow(np.rot90(x[i+1, :, :, 0]))\n",
    "        label_ims.append([label_im])\n",
    "    \n",
    "    dir = 'videos/{name}/ex_{ex}/'.format(name=MODEL_NAME, ex=ex)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    ani = animation.ArtistAnimation(fig, label_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_label_64.mp4'.format(name=MODEL_NAME, ex=ex))\n",
    "\n",
    "    # CREATE THE MODEL'S VIDEO\n",
    "    pred_ims = []\n",
    "    x_i = np.expand_dims(x[0], 0)\n",
    "    for i in range(NUM_FRAMES - 1):\n",
    "        y = model.predict(x_i)\n",
    "        plt.axis('off')\n",
    "        pred_im = plt.imshow(np.rot90(y[0, :, :, 0]))\n",
    "        pred_ims.append([pred_im])\n",
    "        \n",
    "        x_i = np.concatenate((y, np.expand_dims(boundary, (0, -1))), -1)\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, pred_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_pred_64.mp4'.format(name=MODEL_NAME, ex=ex))\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0606d5e76c7e1327171f83de1beba49393fd7daa96a8e17a806b31b3ab97db7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf-39-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
