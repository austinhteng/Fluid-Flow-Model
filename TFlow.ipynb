{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Fluid Flow using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 2D Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(x)\n",
    "    \n",
    "    name = 'basic_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu')(input)\n",
    "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, 1, padding='same')(x)\n",
    "    \n",
    "    name = 'basic_3d_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn((64, 64, 4), 3, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(x, n_filters):\n",
    "    x = layers.Conv2D(\n",
    "        n_filters, (3, 3), padding='same', activation='relu'\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(\n",
    "        n_filters, (3, 3), padding='same', activation='relu'\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_down(x, n_filters):\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    skip = layers.MaxPooling2D(padding='same')(x)\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_up(x, skip, n_filters):\n",
    "    x = layers.Conv2DTranspose(\n",
    "        n_filters, 2, 2, padding='same'\n",
    "    )(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "    \n",
    "    # downsampling\n",
    "    d1, p1 = unet_down(input, n_filters)\n",
    "    d2, p2 = unet_down(p1, n_filters*2)\n",
    "    d3, p3 = unet_down(p2, n_filters*4)\n",
    "    d4, p4 = unet_down(p3, n_filters*8)\n",
    "    \n",
    "    # bottleneck\n",
    "    b = unet_conv_block(p4, n_filters*16)\n",
    "    \n",
    "    # upsampling\n",
    "    u1 = unet_up(b, d4, n_filters*8)\n",
    "    u2 = unet_up(u1, d3, n_filters*4)\n",
    "    u3 = unet_up(u2, d2, n_filters*2)\n",
    "    u4 = unet_up(u3, d1, n_filters)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(u4)\n",
    "    \n",
    "    name = 'unet{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet((64, 64, 4), 3, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 3D Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_3d_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(input)\n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling3D((1, 2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling3D((1, 2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv3D(out_c, 1, (8, 1, 1), padding='same')(x)\n",
    "    \n",
    "    name = 'basic_3d_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_3d_cnn((2, 64, 64, 4), 1, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(input_shape, out_c, n_filters=8):\n",
    "    input = layers.Input(input_shape)\n",
    "\n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters*2,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters*4,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(\n",
    "        filters=n_filters*2, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.Conv3D(\n",
    "        filters=n_filters, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv3D(\n",
    "        filters=out_c, kernel_size=1, strides=(2, 1, 1), padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    # Next, we will build the complete model and compile it.\n",
    "    name = 'cnn_lstm{n_filters}'.format(n_filters=n_filters)\n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_lstm((2, 64, 64, 4), 1, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = 'data/sim_np/size64/sim_512x64x64x64x3.npy'\n",
    "dataset = np.load(fpath)\n",
    "fpath = 'data/sim_np/size64/bound_64x64.npy'\n",
    "boundary = np.load(fpath)\n",
    "\n",
    "# # Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "print(\"Training Dataset Shape:\", train_dataset.shape)\n",
    "print(\"Validation Dataset Shape:\", val_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 2D Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_2d(x):\n",
    "    return x.reshape(x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4])\n",
    "\n",
    "def shift_frames_2d(data, boundary):\n",
    "    x = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4] + 1), np.float16)\n",
    "    y = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4]), np.float16)\n",
    "    boundary = np.expand_dims(boundary, axis=-1)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1] - 1):\n",
    "            \n",
    "            x[i, j] = np.concatenate((data[i, j], boundary), axis=-1)\n",
    "            y[i, j] = data[i, j + 1]\n",
    "        \n",
    "    return unroll_2d(x), unroll_2d(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the processing function to the datasets.\n",
    "x_train_2d, y_train_2d = shift_frames_2d(train_dataset, boundary)\n",
    "x_val_2d, y_val_2d = shift_frames_2d(val_dataset, boundary)\n",
    "\n",
    "print(\"2D Training Dataset Shapes: \" + str(x_train_2d.shape) + \", \" + str(y_train_2d.shape))\n",
    "print(\"2D Validation Dataset Shapes: \" + str(x_val_2d.shape) + \", \" + str(y_val_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3D Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_frames_3d(data, boundary):\n",
    "    N = data.shape[1] - N_PREV_FRAMES\n",
    "    x = np.zeros((data.shape[0]*N, N_PREV_FRAMES, data.shape[2], data.shape[3], 4), np.float16)\n",
    "    y = np.zeros((data.shape[0]*N, 1, data.shape[2], data.shape[3], 3), np.float16)\n",
    "    \n",
    "    boundary = np.expand_dims(boundary, -1)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(N):\n",
    "            # append all the frames to a single list\n",
    "            frames = []\n",
    "            for f in range(N_PREV_FRAMES):\n",
    "                frames.append(np.concatenate((data[i, j+f, :, :, :], boundary), -1))\n",
    "            \n",
    "            x[i*N+j] = np.stack(frames, 0)\n",
    "            y[i*N+j] = np.expand_dims(data[0, j+N_PREV_FRAMES, :, :, :], (0))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PREV_FRAMES = 2\n",
    "x_train_3d, y_train_3d = shift_frames_3d(train_dataset, boundary)\n",
    "x_val_3d, y_val_3d = shift_frames_3d(val_dataset, boundary)\n",
    "\n",
    "print(\"3D Training Dataset Shapes: \" + str(x_train_3d.shape) + \", \" + str(y_train_3d.shape))\n",
    "print(\"3D Validation Dataset Shapes: \" + str(x_val_3d.shape) + \", \" + str(y_val_3d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define modifiable training hyperparameters.\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=0)\n",
    "\n",
    "# create model to train\n",
    "# model = unet((64, 64, 4), 3, 16)\n",
    "model = cnn_lstm(x_train_3d[0].shape, 3, 8)\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "# fit data to model\n",
    "history = model.fit(\n",
    "    x_train_3d,\n",
    "    y_train_3d,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (x_val_3d, y_val_3d),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/keras/{name}'.format(name=model.name))\n",
    "# model = keras.models.load_model('models/keras/unet16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate the Labels and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.animation as animation\n",
    "import os \n",
    "%matplotlib inline\n",
    "\n",
    "FPS = 24\n",
    "INTERVAL = 1000.0/FPS\n",
    "# NUM_EXAMPLES = val_dataset.shape[0]\n",
    "NUM_EXAMPLES = 16\n",
    "MODEL_NAME = model.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animating 2D Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_2d(x, boundary):\n",
    "    return np.concatenate((x, np.expand_dims(boundary, (0, -1))), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex_i in range(NUM_EXAMPLES):\n",
    "    x = val_dataset[ex_i]\n",
    "    \n",
    "    # CREATE THE LABEL VIDEO\n",
    "    fig = plt.figure()\n",
    "    label_ims = []\n",
    "    for i in range(x.shape[0] - 1):\n",
    "        plt.axis('off')\n",
    "        label_im = plt.imshow(np.rot90(x[i+1, :, :, 0]))\n",
    "        label_ims.append([label_im])\n",
    "    \n",
    "    dir = 'videos/{name}/ex_{ex}/'.format(name=MODEL_NAME, ex=ex_i)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    ani = animation.ArtistAnimation(fig, label_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_label_64.mp4')\n",
    "\n",
    "    # CREATE THE MODEL'S VIDEO\n",
    "    pred_ims = []\n",
    "    x_i = format_2d(np.expand_dims(x[0], 0), boundary)\n",
    "    for i in range(x.shape[0] - 1):\n",
    "        y = model.predict(x_i)\n",
    "        plt.axis('off')\n",
    "        pred_im = plt.imshow(np.rot90(y[0, :, :, 0]))\n",
    "        pred_ims.append([pred_im])\n",
    "        \n",
    "        x_i = format_2d(y, boundary)\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, pred_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_pred_64.mp4')\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animating 3D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_3d(x, y, i, boundary):\n",
    "    # append all the frames to a single list\n",
    "    frames = []\n",
    "    for f in range(N_PREV_FRAMES-1):\n",
    "        frames.append(np.concatenate((x[i+f, :, :, :], boundary), -1))\n",
    "    frames.append(np.concatenate((y, boundary), -1))\n",
    "    return np.stack(frames, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ex_i in range(NUM_EXAMPLES):\n",
    "    x = val_dataset[ex_i]\n",
    "    \n",
    "    # CREATE THE LABEL VIDEO\n",
    "    fig = plt.figure()\n",
    "    label_ims = []\n",
    "    for i in range(x.shape[0]-N_PREV_FRAMES):\n",
    "        plt.axis('off')\n",
    "        label_im = plt.imshow(np.rot90(y[i+N_PREV_FRAMES, 0, :, :, 0]))\n",
    "        label_ims.append([label_im])\n",
    "    \n",
    "    dir = 'videos/{name}/ex_{ex}/'.format(name=MODEL_NAME, ex=ex_i)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    ani = animation.ArtistAnimation(fig, label_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_label_64.mp4')\n",
    "\n",
    "    # CREATE THE MODEL'S VIDEO\n",
    "    pred_ims = []\n",
    "    x_i = np.expand_dims(x[0], 0)\n",
    "    for i in range(x.shape[0]-N_PREV_FRAMES):\n",
    "        pred = model.predict(x_i)\n",
    "        plt.axis('off')\n",
    "        pred_im = plt.imshow(np.rot90(pred[i, 0, :, :, 0]))\n",
    "        pred_ims.append([pred_im])\n",
    "        \n",
    "        x_i = np.concatenate((y, np.expand_dims(boundary, (0, -1))), -1)\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, pred_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_pred_64.mp4')\n",
    "    \n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0606d5e76c7e1327171f83de1beba49393fd7daa96a8e17a806b31b3ab97db7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf-39-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
