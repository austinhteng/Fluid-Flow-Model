{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating Fluid Flow using Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 2D Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(x)\n",
    "    \n",
    "    name = 'basic_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu')(input)\n",
    "    x = layers.Conv2D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D(padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv2D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, 1, padding='same')(x)\n",
    "    \n",
    "    name = 'basic_3d_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cnn((64, 64, 4), 3, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_conv_block(x, n_filters):\n",
    "    x = layers.Conv2D(\n",
    "        n_filters, (3, 3), padding='same', activation='relu'\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv2D(\n",
    "        n_filters, (3, 3), padding='same', activation='relu'\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_down(x, n_filters):\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    skip = layers.MaxPooling2D(padding='same')(x)\n",
    "    return x, skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_up(x, skip, n_filters):\n",
    "    x = layers.Conv2DTranspose(\n",
    "        n_filters, 2, 2, padding='same'\n",
    "    )(x)\n",
    "    x = layers.Concatenate()([x, skip])\n",
    "    x = unet_conv_block(x, n_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "    \n",
    "    # downsampling\n",
    "    d1, p1 = unet_down(input, n_filters)\n",
    "    d2, p2 = unet_down(p1, n_filters*2)\n",
    "    d3, p3 = unet_down(p2, n_filters*4)\n",
    "    d4, p4 = unet_down(p3, n_filters*8)\n",
    "    \n",
    "    # bottleneck\n",
    "    b = unet_conv_block(p4, n_filters*16)\n",
    "    \n",
    "    # upsampling\n",
    "    u1 = unet_up(b, d4, n_filters*8)\n",
    "    u2 = unet_up(u1, d3, n_filters*4)\n",
    "    u3 = unet_up(u2, d2, n_filters*2)\n",
    "    u4 = unet_up(u3, d1, n_filters)\n",
    "    \n",
    "    output = layers.Conv2D(out_c, (1, 1), padding='same')(u4)\n",
    "    \n",
    "    name = 'unet{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet((64, 64, 4), 3, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing 3D Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic 3D CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_3d_cnn(input_shape, out_c, n_filters=8):\n",
    "    input = keras.Input(input_shape)\n",
    "      \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(input)\n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling3D((1, 2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.MaxPooling3D((1, 2, 2), padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.Conv3D(n_filters * 4, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3DTranspose(n_filters * 2, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv3D(n_filters * 2, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3DTranspose(n_filters, 2, 2, padding='same')(x)\n",
    "    \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)    \n",
    "    x = layers.Conv3D(n_filters, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv3D(out_c, 1, (8, 1, 1), padding='same')(x)\n",
    "    \n",
    "    name = 'basic_3d_cnn{n_filters}'.format(n_filters=n_filters)\n",
    "    \n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_3d_cnn((2, 64, 64, 2), 1, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_lstm(input_shape, out_c, n_filters=8):\n",
    "    input = layers.Input(input_shape)\n",
    "\n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters*2,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.ConvLSTM2D(\n",
    "        filters=n_filters*4,\n",
    "        kernel_size=3,\n",
    "        padding=\"same\",\n",
    "        return_sequences=True,\n",
    "        activation=\"relu\",\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Conv3D(\n",
    "        filters=n_filters*2, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    x = layers.Conv3D(\n",
    "        filters=n_filters, kernel_size=3, activation=\"relu\", padding=\"same\"\n",
    "    )(x)\n",
    "    \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    output = layers.Conv3D(\n",
    "        filters=out_c, kernel_size=1, padding=\"same\"\n",
    "    )(x)\n",
    "\n",
    "    # Next, we will build the complete model and compile it.\n",
    "    name = 'cnn_lstm{n_filters}'.format(n_filters=n_filters)\n",
    "    return keras.Model(input, output, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_lstm8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2, 64, 64, 4)]    0         \n",
      "                                                                 \n",
      " conv_lstm2d_3 (ConvLSTM2D)  (None, 2, 64, 64, 8)      3488      \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 2, 64, 64, 8)     32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_4 (ConvLSTM2D)  (None, 2, 64, 64, 16)     13888     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 2, 64, 64, 16)    64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv_lstm2d_5 (ConvLSTM2D)  (None, 2, 64, 64, 32)     55424     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 2, 64, 64, 32)    128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_3 (Conv3D)           (None, 2, 64, 64, 16)     13840     \n",
      "                                                                 \n",
      " conv3d_4 (Conv3D)           (None, 2, 64, 64, 8)      3464      \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 2, 64, 64, 8)     32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv3d_5 (Conv3D)           (None, 2, 64, 64, 1)      9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 90,369\n",
      "Trainable params: 90,241\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_lstm((2, 64, 64, 4), 1, 8).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Shape: (460, 64, 64, 64, 3)\n",
      "Validation Dataset Shape: (52, 64, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "fpath = 'data/sim_np/size64/sim_512x64x64x64x3.npy'\n",
    "dataset = np.load(fpath)\n",
    "fpath = 'data/sim_np/size64/bound_64x64.npy'\n",
    "boundary = np.load(fpath)\n",
    "\n",
    "# # Split into train and validation sets using indexing to optimize memory.\n",
    "indexes = np.arange(dataset.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "train_index = indexes[: int(0.9 * dataset.shape[0])]\n",
    "val_index = indexes[int(0.9 * dataset.shape[0]) :]\n",
    "train_dataset = dataset[train_index]\n",
    "val_dataset = dataset[val_index]\n",
    "\n",
    "print(\"Training Dataset Shape:\", train_dataset.shape)\n",
    "print(\"Validation Dataset Shape:\", val_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating 2D Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll_2d(x):\n",
    "    return x.reshape(x.shape[0]*x.shape[1], x.shape[2], x.shape[3], x.shape[4])\n",
    "\n",
    "def shift_frames_2d(data, boundary):\n",
    "    x = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4] + 1), np.float16)\n",
    "    y = np.zeros((data.shape[0], data.shape[1] - 1, data.shape[2], data.shape[3], data.shape[4]), np.float16)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1] - 1):\n",
    "            \n",
    "            x[i, j] = np.concatenate((data[i, j], np.expand_dims(boundary, axis=-1)), axis=-1)\n",
    "            y[i, j] = data[i, j + 1]\n",
    "        \n",
    "    return unroll_2d(x), unroll_2d(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the processing function to the datasets.\n",
    "x_train_2d, y_train_2d = shift_frames_2d(train_dataset, boundary)\n",
    "x_val_2d, y_val_2d = shift_frames_2d(val_dataset, boundary)\n",
    "\n",
    "print(\"2D Training Dataset Shapes: \" + str(x_train_2d.shape) + \", \" + str(y_train_2d.shape))\n",
    "print(\"2D Validation Dataset Shapes: \" + str(x_val_2d.shape) + \", \" + str(y_val_2d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 3D Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0, 0, :, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_frames_3d(data, boundary, n_prev_frames=2):\n",
    "    N = data.shape[1] - n_prev_frames\n",
    "    x = np.zeros((data.shape[0]*N, n_prev_frames, data.shape[2], data.shape[3], 4), np.float16)\n",
    "    y = np.zeros((data.shape[0]*N, 1, data.shape[2], data.shape[3], 1), np.float16)\n",
    "    \n",
    "    boundary = np.expand_dims(boundary, -1)\n",
    "    \n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(N):\n",
    "            frames = []\n",
    "            for f in range(n_prev_frames):\n",
    "                frames.append(np.concatenate((data[i, j+f, :, :, :], boundary), -1))\n",
    "            x[i*N+j] = np.stack(frames, 0)\n",
    "            y[i*N+j] = np.expand_dims(data[0, j+n_prev_frames, :, :, 0], (-1, 0))\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D Training Dataset Shapes: (28520, 2, 64, 64, 4), (28520, 1, 64, 64, 1)\n",
      "3D Validation Dataset Shapes: (3224, 2, 64, 64, 4), (3224, 1, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train_3d, y_train_3d = shift_frames_3d(train_dataset, boundary, 2)\n",
    "x_val_3d, y_val_3d = shift_frames_3d(val_dataset, boundary, 2)\n",
    "\n",
    "print(\"3D Training Dataset Shapes: \" + str(x_train_3d.shape) + \", \" + str(y_train_3d.shape))\n",
    "print(\"3D Validation Dataset Shapes: \" + str(x_val_3d.shape) + \", \" + str(y_val_3d.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "  3/223 [..............................] - ETA: 17:39 - loss: 0.4077"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sj/Documents/Programming/Research/Tensorflow/TFlow copy.ipynb Cell 31'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=11'>12</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=12'>13</a>\u001b[0m     loss\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mMeanSquaredError(), optimizer\u001b[39m=\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=13'>14</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=15'>16</a>\u001b[0m \u001b[39m# fit data to model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=16'>17</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=17'>18</a>\u001b[0m     x_train_3d,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=18'>19</a>\u001b[0m     y_train_3d,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=19'>20</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=20'>21</a>\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=21'>22</a>\u001b[0m     validation_data \u001b[39m=\u001b[39;49m (x_val_3d, y_val_3d),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=22'>23</a>\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping, reduce_lr],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sj/Documents/Programming/Research/Tensorflow/TFlow%20copy.ipynb#ch0000029?line=23'>24</a>\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///opt/homebrew/Caskroom/miniconda/base/envs/tf-39-cpu/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# define modifiable training hyperparameters.\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# define some callbacks to improve training.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=0)\n",
    "\n",
    "# create model to train\n",
    "# model = unet((64, 64, 4), 3, 16)\n",
    "model = cnn_lstm(x_train_3d[0].shape, 1, 8)\n",
    "model.compile(\n",
    "    loss=keras.losses.MeanSquaredError(), optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "# fit data to model\n",
    "history = model.fit(\n",
    "    x_train_3d,\n",
    "    y_train_3d,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data = (x_val_3d, y_val_3d),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/keras/{name}'.format(name=model.name))\n",
    "# model = keras.models.load_model('models/keras/unet16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animate the Labels and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_input(dataset, boundary, example_i):\n",
    "    boundary = np.repeat(np.expand_dims(boundary, (0, -1)), 64, 0)\n",
    "    data = dataset[example_i]\n",
    "    return np.concatenate((data, boundary), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "import matplotlib.animation as animation\n",
    "import os \n",
    "%matplotlib inline\n",
    "\n",
    "FPS = 24\n",
    "INTERVAL = 1000.0/FPS\n",
    "# NUM_EXAMPLES = val_dataset.shape[0]\n",
    "NUM_EXAMPLES = 16\n",
    "NUM_FRAMES = val_dataset.shape[1]\n",
    "MODEL_NAME = model.name\n",
    "\n",
    "for ex in range(NUM_EXAMPLES):\n",
    "    x = data_to_input(val_dataset, boundary, ex)\n",
    "    \n",
    "    # CREATE THE LABEL VIDEO\n",
    "    fig = plt.figure()\n",
    "    label_ims = []\n",
    "    for i in range(NUM_FRAMES - 1):\n",
    "        plt.axis('off')\n",
    "        label_im = plt.imshow(np.rot90(x[i+1, :, :, 0]))\n",
    "        label_ims.append([label_im])\n",
    "    \n",
    "    dir = 'videos/{name}/ex_{ex}/'.format(name=MODEL_NAME, ex=ex)\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "    ani = animation.ArtistAnimation(fig, label_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_label_64.mp4'.format(name=MODEL_NAME, ex=ex))\n",
    "\n",
    "    # CREATE THE MODEL'S VIDEO\n",
    "    pred_ims = []\n",
    "    x_i = np.expand_dims(x[0], 0)\n",
    "    for i in range(NUM_FRAMES - 1):\n",
    "        y = model.predict(x_i)\n",
    "        plt.axis('off')\n",
    "        pred_im = plt.imshow(np.rot90(y[0, :, :, 0]))\n",
    "        pred_ims.append([pred_im])\n",
    "        \n",
    "        x_i = np.concatenate((y, np.expand_dims(boundary, (0, -1))), -1)\n",
    "\n",
    "    ani = animation.ArtistAnimation(fig, pred_ims, interval=INTERVAL, blit=True, repeat_delay=1000)\n",
    "    ani.save(dir+'water_pred_64.mp4'.format(name=MODEL_NAME, ex=ex))\n",
    "    \n",
    "    plt.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0606d5e76c7e1327171f83de1beba49393fd7daa96a8e17a806b31b3ab97db7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('tf-39-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
